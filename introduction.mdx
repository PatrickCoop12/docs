---
title: Introduction
icon: "flag"
description: "Simli lets developers create Lipsynced AI avatars. Ready to make your first one? Your journey begins here."
---

## An API with endless possibilities.

With visual lipsynced AI avatars like our API gives you, anything is possible: mock interviews, sales assistants, language training, coaching, CS training, historical characters and so much more. [Try our demo](https://www.simli.com/demo).

<Frame>
  <img src="/Background_avatars.gif" ></img>
</Frame>

## How it works?
Using our `LipsyncStream` API is simple. Through a bi-directional websocket communication, you send us audio and we send you back video and audio frames.

You can then use these video and audio frame bytes to render video and playback audio in sync. You can also use our `Simli-React-SDK` to handle WebSocket communication, decode received bytes and sync audio & video playback.

<Info>
We encourage you to learn more about [LipsyncStream WebSocket](/api-reference/endpoint/LipsyncStream)
</Info>

## Sample Repos

We built some sample repos to get you started

<Card
  title="simli-retell-react-demo"
  icon="github"
  href="https://github.com/simliai/simli-retell-frontend-reactjs-demo"
>
  Integrating Retell conversational AI bot with Simli-React-SDK
</Card>
<Card
  title="simli-radio-next-demo"
  icon="github"
  href="https://github.com/simliai/simli-radio-next-js-demo"
>
  Stream incoming audio from a radio broadcast to Simli-React-SDK to process and return lipsynced video and audio frames.
</Card>
<Card
  title="simli-radio-python-demo"
  icon="github"
  href="https://github.com/simliai/RadioDemo"
>
  This is a showcase of the Simli Lipsync API in action. The demo works by getting an mp3 radio stream, converting it to pcm16 using ffmpeg and sending the pcm16 frames to the Simli Lipsync API over websockets.
</Card>



### Get started in 10 minutes
<Card title="Get Started" icon="bolt" href="/get-started">
  Start building with our Simli-React-SDK
</Card>


